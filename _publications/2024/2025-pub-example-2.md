---
title:          "Learning Phonetic Context-Dependent Viseme for Enhancing Speech-Driven 3D Facial Animation"
date:           2025-08-22 00:01:00 +0800
selected:       true
pub:            "Interspeech"
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Oral</span>'
pub_date:       "2025"

# abstract: >-
#   This study explores the potential of multimodal large language models in scene text segmentation by leveraging semantic-enhanced features. It demonstrates the synergy between textual and visual modalities to improve segmentation tasks.
cover:          /assets/images/covers/interspeech25.png
authors:
  - <u>Hyung Kyu Kim</u>
  - Hak Gu Kim
links:
  # Paper: "https://ieeexplore.ieee.org/abstract/document/10769199"
  Project Page: "https://cau-irislab.github.io/interspeech25/"
  Code: "https://github.com/kimhyungkyu-1208/interspeech25"
---